{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "# the following two import statements provide the implemetation for Selenium Waits\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "s = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "house_link = \"https://www.politico.com/2022-election/results/\"\n",
    "driver.get(house_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the page source\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Parse the page source using Beautiful Soup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Find the table that contains the list of states\n",
    "container = soup.find('div','styles_columns-container__Kq5vS')\n",
    "\n",
    "# Extract the list of states from the table\n",
    "states = [state.get_text(strip=True) for state in container.find_all('a')]\n",
    "\n",
    "# Print the list of states\n",
    "print(states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_link = [state.replace(' ', '-') for state in states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (states_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pd.DataFrame(columns=['Candidate', 'Party', 'Votes', 'Pct%','State', 'District'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "final_results = {}\n",
    "\n",
    "for index, link in enumerate(states_link):\n",
    "    print(index, 'Loading Data for', states[index])\n",
    "    result = {}\n",
    "    driver.get(house_link + str(link.lower())+'/house/')\n",
    "    try:\n",
    "        buttons = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '[title=\"Expand\"]')))\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, '[title=\"Expand\"]')\n",
    "        print(' -----',len(buttons), 'button found.')\n",
    "        for button in buttons:\n",
    "            button.click() \n",
    "            print(states[index], button.text, 'clicked')\n",
    "        buttons = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '[title=\"Expand\"]')))\n",
    "        buttons = driver.find_elements(By.CSS_SELECTOR, '[title=\"Expand\"]')\n",
    "        print(' -----',len(buttons), 'button found.')\n",
    "        for button in buttons:\n",
    "            button.click() \n",
    "            print(states[index], button.text, 'clicked')\n",
    "    except:\n",
    "        print(states[index],'no button found')\n",
    "    # start scraping districts\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    #print(soup)\n",
    "\n",
    "    container = soup.find('div',{'class':'styles_table-container__vTHda'})\n",
    "\n",
    "    districts = container.find_all('h5')\n",
    "\n",
    "    districts = [district.get_text(strip=True) for district in districts]\n",
    "\n",
    "\n",
    "    #scrapping candidate\n",
    "    sections = []\n",
    "    sub_list = []\n",
    "    if container.find_all('div',{'class':'styles_left-title__rNUfI'}):\n",
    "        sections = container.find_all('div',{'class':'styles_left-title__rNUfI'})\n",
    "    \n",
    "    \n",
    "    if sections != []:\n",
    "        \n",
    "        for section_index, section in enumerate(sections):\n",
    "            candidates = section.find_all('td')\n",
    "            new_list = []\n",
    "\n",
    "            list1 = [candidate.get_text(strip=True) for candidate in candidates]\n",
    "            for item in list1:\n",
    "                if '(' in item:\n",
    "                    x = item.split('(')\n",
    "                    for y in x:\n",
    "                        new_list.append(y)\n",
    "            \n",
    "                elif item =='':\n",
    "                    new_list.append('0')\n",
    "                    new_list.append('0%')\n",
    "                elif item.replace(',','').isdigit() == False and '%' not in item and item!= 'Uncontested' and item !='':\n",
    "                    new_list.append(item)\n",
    "                    new_list.append('Other Party')\n",
    "                elif 'Uncontested' == item:\n",
    "                    next\n",
    "                \n",
    "                else: new_list.append(item)\n",
    "            \n",
    "            N = 4\n",
    "            temp_list = [new_list[n:n+N] for n in range(0,len(new_list), N)]\n",
    "            for sublist in temp_list:\n",
    "                sublist.append(states[index])\n",
    "                sublist.append(districts[section_index])\n",
    "            sub_list.extend(temp_list)\n",
    "            \n",
    "\n",
    "                    \n",
    "    else: \n",
    "        candidates = container.find_all('td')\n",
    "        list1 = [candidate.get_text(strip=True) for candidate in candidates]\n",
    "        new_list = []\n",
    "        for item in list1:\n",
    "            if '(' in item:\n",
    "                x = item.split('(')\n",
    "                for y in x:\n",
    "                    new_list.append(y)\n",
    "            elif item =='':\n",
    "                new_list.append('0')\n",
    "                new_list.append('0.00%')\n",
    "            elif item.replace(',','').isdigit() == False and '%' not in item and item!= 'Uncontested' and item !='':\n",
    "                new_list.append(item)\n",
    "                new_list.append('Other Party')\n",
    "            elif 'Uncontested' == item:\n",
    "                next\n",
    "                \n",
    "            else: new_list.append(item)\n",
    "        \n",
    "        N=4\n",
    "        \n",
    "        sub_list = [new_list[n:n+N] for n in range(0,len(new_list), N)]\n",
    "        for list in sub_list:\n",
    "            list.append(states[index])\n",
    "            list.append('At Large')\n",
    "\n",
    "    new_df = pd.DataFrame(sub_list, columns = df.columns)\n",
    "    df = pd.concat([df, new_df])\n",
    "    \n",
    "\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "\n",
    "print(count , 'states scraped')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Candidate'] != 'Hide other candidates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incumbent = ['Incumbent' if '*' in candidate else '/' for candidate in df['Candidate']]\n",
    "df['Incumbent'] = incumbent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Party'] = df['Party'].replace('\\)','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party_dict = {'R': 'Republician', 'D': 'Democratic', 'Ind.': 'Independent Party'}\n",
    "df['Party'] = df['Party'].replace(party_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_to_code = {\n",
    "            \"Alabama\": \"AL\",\n",
    "            \"Alaska\": \"AK\",\n",
    "            \"Arizona\": \"AZ\",\n",
    "            \"Arkansas\": \"AR\",\n",
    "            \"California\": \"CA\",\n",
    "            \"Colorado\": \"CO\",\n",
    "            \"Connecticut\": \"CT\",\n",
    "            \"Delaware\": \"DE\",\n",
    "            \"Florida\": \"FL\",\n",
    "            \"Georgia\": \"GA\",\n",
    "            \"Hawaii\": \"HI\",\n",
    "            \"Idaho\": \"ID\",\n",
    "            \"Illinois\": \"IL\",\n",
    "            \"Indiana\": \"IN\",\n",
    "            \"Iowa\": \"IA\",\n",
    "            \"Kansas\": \"KS\",\n",
    "            \"Kentucky\": \"KY\",\n",
    "            \"Louisiana\": \"LA\",\n",
    "            \"Maine\": \"ME\",\n",
    "            \"Maryland\": \"MD\",\n",
    "            \"Massachusetts\": \"MA\",\n",
    "            \"Michigan\": \"MI\",\n",
    "            \"Minnesota\": \"MN\",\n",
    "            \"Mississippi\": \"MS\",\n",
    "            \"Missouri\": \"MO\",\n",
    "            \"Montana\": \"MT\",\n",
    "            \"Nebraska\": \"NE\",\n",
    "            \"Nevada\": \"NV\",\n",
    "            \"New Hampshire\": \"NH\",\n",
    "            \"New Jersey\": \"NJ\",\n",
    "            \"New Mexico\": \"NM\",\n",
    "            \"New York\": \"NY\",\n",
    "            \"North Carolina\": \"NC\",\n",
    "            \"North Dakota\": \"ND\",\n",
    "            \"Ohio\": \"OH\",\n",
    "            \"Oklahoma\": \"OK\",\n",
    "            \"Oregon\": \"OR\",\n",
    "            \"Pennsylvania\": \"PA\",\n",
    "            \"Rhode Island\": \"RI\",\n",
    "            \"South Carolina\": \"SC\",\n",
    "            \"South Dakota\": \"SD\",\n",
    "            \"Tennessee\": \"TN\",\n",
    "            \"Texas\": \"TX\",\n",
    "            \"Utah\": \"UT\",\n",
    "            \"Vermont\": \"VT\",\n",
    "            \"Virginia\": \"VA\",\n",
    "            \"Washington\": \"WA\",\n",
    "            \"West Virginia\": \"WV\",\n",
    "            \"Wisconsin\": \"WI\",\n",
    "            \"Wyoming\": \"WY\",\n",
    "            \"District of Columbia\": \"DC\",\n",
    "            \"American Samoa\": \"AS\",\n",
    "            \"Guam\": \"GU\",\n",
    "            \"Northern Mariana Islands\": \"MP\",\n",
    "            \"Puerto Rico\": \"PR\",\n",
    "            \"United States Minor Outlying Islands\": \"UM\",\n",
    "            \"U.S. Virgin Islands\": \"VI\",\n",
    "        }\n",
    "\n",
    "df['State Code'] = df['State'].map(us_state_to_code)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Candidate'] = df['Candidate'].replace({'\\*': ''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Votes'] = df['Votes'].replace({',': ''}, regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ['State', 'State Code', 'District', 'Party', 'Candidate', 'Incumbent', 'Votes', 'Pct%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Elected'] = df.groupby(['State', 'District'])['Votes'].transform(max) == df['Votes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party = df['Party'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "won = []\n",
    "for index, item in enumerate(party):\n",
    "    get_index= index\n",
    "    won.append(party[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(won)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Won Party'] = won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_house.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
